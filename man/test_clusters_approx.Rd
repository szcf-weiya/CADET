% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trunc_inf.R
\name{test_clusters_approx}
\alias{test_clusters_approx}
\title{Monte Carlo significance test for any clustering method}
\usage{
test_clusters_approx(
  X,
  k1,
  k2,
  iso = TRUE,
  sig = NULL,
  SigInv = NULL,
  ndraws = 2000,
  cl_fun,
  cl = NULL
)
}
\arguments{
\item{X}{\eqn{n} by \eqn{p} matrix containing numeric data.}

\item{k1, k2}{Integers selecting the clusters to test.}

\item{iso}{Boolean. If \code{TRUE}, isotropic covariance matrix model, otherwise not.}

\item{sig}{Optional scalar specifying \eqn{\sigma}, relevant if \code{iso} is \code{TRUE}.}

\item{SigInv}{Optional matrix specifying \eqn{\Sigma^{-1}}, relevant if \code{iso} is \code{FALSE}.}

\item{ndraws}{Integer selecting the number of importance samples, default of 2000.}

\item{cl_fun}{Function returning assignments to clusters 1 through \code{K}.}

\item{cl}{Optionally pass in the results of calling \code{cl_fun} on your data. This is for
efficiency and reproducibility (when the clustering function is non-deterministic).}
}
\value{
\item{stat}{the test statistic: the Euclidean distance between the mean of cluster \code{k1} and the mean of cluster \code{k2}  }
\item{pval}{the approximate p-value}
\item{stderr}{standard error of the p-value estimate}
\item{clusters}{the estimated cluster assignments}
}
\description{
This function performs a user-specified clustering method \code{cl_fun} on the rows of a 
data matrix to obtain \code{K} clusters, and tests the null hypothesis of no difference in means 
between clusters \code{k1} and \code{k2}.
}
\details{
In order to account for the fact that the clusters have been estimated from the data, 
the p-values are computed conditional on the fact that those clusters were estimated. 
This function approximates p-values via importance sampling. 

This function assumes that \code{cl_fun} takes a \eqn{n \times p} numeric data matrix as input 
and outputs integer assignments to clusters 1 through \code{K}.
}
\examples{
# Simulates a 100 x 2 data set with three clusters
set.seed(123)
dat <- rbind(c(-1, 0), c(0, sqrt(3)), c(1, 0))[rep(1:3, length=100), ] + 
matrix(0.2*rnorm(200), 100, 2)

# Function to run k-means clustering w/ k = 3 and 50 random starts
km_cluster <- function(X) { 
 km <- kmeans(X, 3, nstart=50)
 return(km$cluster)
}

# Cluster data using k-means 
clusters <- km_cluster(dat)
table(rep(1:3, length=100), clusters)

# tests for a difference in means between clusters 1 and 2
# We pass in earlier k-means clustering results from earlier
results <- test_clusters_approx(dat, k1=1, k2=2, cl_fun=km_cluster, ndraws=500, cl=clusters)
results$stat
results$pval
results$stderr

}
\references{
Lucy L. Gao et al. "Selective inference for hierarchical clustering". arXiv preprint (2020).
}
\seealso{
\code{\link{test_clusters_approx_1f}} for approximate p-values for a difference in the mean of one feature.
}
