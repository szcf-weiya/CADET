% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trunc_inf.R
\name{test_complete_hier_clusters_approx_1f}
\alias{test_complete_hier_clusters_approx_1f}
\title{Monte Carlo significance test (with respect to a single feature) for complete linkage hierarchical clustering}
\usage{
test_complete_hier_clusters_approx_1f(
  X,
  hcl,
  K,
  k1,
  k2,
  feat,
  sig = NULL,
  ndraws = 2000
)
}
\arguments{
\item{X}{\eqn{n} by \eqn{p} matrix containing numeric data.}

\item{hcl}{Object of the type \code{hclust} containing the hierarchical clustering of X.}

\item{K}{Integer selecting the total number of clusters.}

\item{k1, k2}{Integers selecting the clusters to test.}

\item{feat}{Integer selecting the feature to test.}

\item{sig}{Optional scalar specifying \eqn{\sigma}.}

\item{ndraws}{Integer selecting the number of importance samples, default of 2000.}
}
\value{
\item{stat}{the test statistic: the absolute difference between the mean of feature \code{feat} in cluster \code{k1} and the mean of feature \code{feat} in cluster \code{k2}}
\item{pval}{the approximate p-value}
\item{stderr}{standard error of the p-value estimate}
}
\description{
This tests the null hypothesis of no difference in means in the mean of
feature \code{feat} between clusters \code{k1} and \code{k2} at
level \code{K} in a complete linkage hierarchical clustering. (The \code{K}
clusters are  numbered as per the results of the \code{cutree} function in the
\code{stats} package.)
}
\details{
Important note: Before calling \code{hclust} and this function, make sure to
load the package \code{fastcluster}. This is because the p-value approximation
procedure requires running hierarchical clustering on a large number of simulated
data sets, and the version of \code{hclust} in the \code{fastcluster} package
is much faster than the version of \code{hclust} in \code{stats}.

In order to account for the fact that the clusters have been estimated from the data,
the p-values are computed conditional on the fact that those clusters were estimated.
This function approximates p-values via importance sampling.

Currently, this function supports squared Euclidean distance as a measure of dissimilarity
between observations. (Note that complete linkage is invariant under monotone transformations
of the measure of dissimilarity between observations, so unsquared Euclidean distance
would produce the same hierarchical clustering.)

This function assumes that the covariance matrix of the features is isotropic
i.e. \eqn{Cov(X_i) = \sigma^2 I_p}. If known, \eqn{\sigma} can be passed in using the \code{sigma}
argument; otherwise, an estimate of \eqn{\sigma} will be used.
}
\examples{
# Simulates a 100 x 2 data set with no clusters
set.seed(1)
dat <-  matrix(rnorm(200), 100, 2)

# Complete linkage hierarchical clustering
library(fastcluster)
hcl <- hclust(dist(dat, method="euclidean")^2, method="complete")

# plot dendrograms with the 1st and 2nd clusters (cut at the third split)
# displayed in blue and orange
plot(hcl)
rect_hier_clusters(hcl, k=3, which=1:2, border=c("blue", "orange"))

# Monte Carlo test for a difference in means between the blue and orange clusters
# wrt the 2nd feature
test_complete_hier_clusters_approx_1f(X=dat, hcl=hcl,
K=3, k1=1, k2=2, feat=2, ndraws=1000)

}
\references{
Lucy L. Gao et al. "Selective inference for hierarchical clustering". arXiv preprint (2020).
}
\seealso{
\code{\link{rect_hier_clusters}} for visualizing clusters \code{k1} and \code{k2} in the dendrogram;

\code{\link{test_hier_clusters_exact_1f}} for exact p-values for other linkages;

\code{\link{test_clusters_approx_1f}} for approximate p-values for a user-specified clustering function;

\code{\link{test_complete_hier_clusters_approx}} for approximate p-values for a difference in the mean of any feature.
}
